"""
ComfyUI è‡ªå®šä¹‰èŠ‚ç‚¹ï¼šCharacterTagSelector
- æ‰«æ web/data ä¸‹çš„å¤šä¸ª JSON æ–‡ä»¶ä½œä¸ºæ•°æ®æº
- generate_tag ä¼šæŒ‰å½“å‰é€‰ä¸­çš„ json_file æŸ¥æ‰¾è§’è‰²å¹¶è¾“å‡ºæ ‡ç­¾ + é¢„è§ˆå›¾
"""

from collections import OrderedDict
import threading
import tempfile
import shutil
import os
import json
import hashlib
from io import BytesIO
from typing import Dict, List, Tuple, Optional
import folder_paths

import numpy as np
import requests
import torch
from PIL import Image

# å¯é€‰ï¼šå¦‚æœä½ æƒ³è®©å‰ç«¯é€šè¿‡æ¥å£åŠ¨æ€æ‹‰å–è§’è‰²åˆ—è¡¨
from aiohttp import web
try:
    from server import PromptServer
except Exception:
    PromptServer = None


class CharacterTagSelector:
    """è§’è‰²æ ‡ç­¾é€‰æ‹©å™¨èŠ‚ç‚¹"""

    OUTPUT_TYPES_MAP = {
        "Danbooruæ ‡ç­¾": "danbooru_tag",
        "è‹±æ–‡è‡ªç„¶è¯­è¨€": "natural_en",
        "ä¸­æ–‡è‡ªç„¶è¯­è¨€": "natural_cn",
        "ä¸­æ–‡å + ä½œå“å": "cn_name_source",
    }

    # full_path -> (mtime, data)
    _data_cache: Dict[str, Tuple[float, List[Dict]]] = {}

    # url_md5 -> image_tensor
    # _image_cache: Dict[str, torch.Tensor] = {}

    # ===== å›¾ç‰‡ç¼“å­˜ç­–ç•¥ =====
    # å†…å­˜ï¼šLRU tensor ç¼“å­˜ï¼ˆå¼ºé™åˆ¶ï¼Œé¿å… OOMï¼‰
    _tensor_lru: "OrderedDict[str, torch.Tensor]" = OrderedDict()
    _tensor_lru_bytes: int = 0
    _MAX_MEM_CACHE_ITEMS: int = 64           # æœ€å¤šç¼“å­˜ 64 å¼  tensor
    _MAX_MEM_CACHE_BYTES: int = 256 * 1024 * 1024  # æˆ–æœ€å¤š 256MBï¼ˆæŒ‰éœ€è°ƒå°/è°ƒå¤§ï¼‰

    # ç¡¬ç›˜ï¼šæŒä¹…åŒ–ç¼“å­˜ï¼ˆwebp + sha256 æ ¡éªŒï¼‰
    _MAX_DOWNLOAD_BYTES: int = 10 * 1024 * 1024  # å•å¼ æœ€å¤šä¸‹è½½ 10MBï¼Œé¿å…è¶…å¤§æ–‡ä»¶
    _USER_AGENT: str = (
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
        "AppleWebKit/537.36 (KHTML, like Gecko) "
        "Chrome/120.0.0.0 Safari/537.36"
    )
    _request_headers = {
        "User-Agent": _USER_AGENT,
        "Accept": "image/avif,image/webp,image/apng,image/*,*/*;q=0.8",
        "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8",
        "Connection": "keep-alive",
    }

    # å¹¶å‘ä¸‹è½½ä¿æŠ¤ï¼ˆé¿å…åŒä¸€ URL å¤šæ¬¡ä¸‹è½½ï¼‰
    _url_locks: Dict[str, threading.Lock] = {}
    _url_locks_guard = threading.Lock()

     # signature -> all_character_choices
    _all_character_choices_cache: Tuple[str, List[str]] = ("", [])

    @classmethod
    def get_all_character_choices(cls) -> List[str]:
        """
        è¿”å› web/data ä¸‹æ‰€æœ‰ JSON çš„è§’è‰² displayName å¹¶é›†ï¼ˆå»é‡ï¼‰ã€‚
        ç”¨æ–‡ä»¶ mtime åšç®€å•ç¼“å­˜ï¼Œé¿å…æ¯æ¬¡ INPUT_TYPES éƒ½å…¨é‡è§£æã€‚
        """
        files = cls.get_available_json_files()
        # æ„é€ ç­¾åï¼šæ–‡ä»¶å + mtimeï¼Œä»»ä½•æ–‡ä»¶æ›´æ–°éƒ½ä¼šå¯¼è‡´ç­¾åå˜åŒ–
        sig_parts: List[str] = []
        for f in files:
            full = cls._resolve_json_path(f)
            if full and os.path.exists(full):
                sig_parts.append(f"{os.path.basename(full)}:{os.path.getmtime(full)}")
        signature = "|".join(sig_parts)

        if cls._all_character_choices_cache[0] == signature:
            return cls._all_character_choices_cache[1]

        names = set()
        for f in files:
            if not f or f == "æœªæ‰¾åˆ°JSONæ–‡ä»¶":
                continue
            lst = cls.get_character_list_for_file(f)
            for n in lst:
                if n and n != "æœªåŠ è½½è§’è‰²æ•°æ®":
                    names.add(n)

        all_choices = sorted(names)
        if not all_choices:
            all_choices = ["æœªåŠ è½½è§’è‰²æ•°æ®"]

        cls._all_character_choices_cache = (signature, all_choices)
        return all_choices

    @classmethod
    def get_data_dir(cls) -> str:
        """web/data ç›®å½•ç»å¯¹è·¯å¾„"""
        current_dir = os.path.dirname(os.path.abspath(__file__))
        return os.path.join(current_dir, "web", "data")

    @classmethod
    def get_available_json_files(cls) -> List[str]:
        """æ‰«æ web/data ä¸‹çš„ .json æ–‡ä»¶ååˆ—è¡¨"""
        data_dir = cls.get_data_dir()

        if not os.path.exists(data_dir):
            print(f"âš ï¸ dataç›®å½•ä¸å­˜åœ¨: {data_dir}")
            return ["æœªæ‰¾åˆ°JSONæ–‡ä»¶"]

        json_files: List[str] = []
        try:
            for filename in os.listdir(data_dir):
                if filename.lower().endswith(".json"):
                    json_files.append(filename)
        except Exception as e:
            print(f"âŒ æ‰«ædataç›®å½•å¤±è´¥: {e}")
            return ["æœªæ‰¾åˆ°JSONæ–‡ä»¶"]

        if not json_files:
            return ["æœªæ‰¾åˆ°JSONæ–‡ä»¶"]

        json_files.sort()
        return json_files

    @classmethod
    def _resolve_json_path(cls, json_file: str) -> str:
        """
        è§£æ json_fileï¼ˆæ–‡ä»¶åæˆ–è·¯å¾„ï¼‰åˆ° data_dir å†…çš„ç»å¯¹è·¯å¾„ã€‚
        ä¸ºå®‰å…¨èµ·è§ï¼Œåªå…è®¸è®¿é—® data_dir å†…çš„æ–‡ä»¶ã€‚
        """
        if not json_file or str(json_file).strip() == "" or json_file == "æœªæ‰¾åˆ°JSONæ–‡ä»¶":
            return ""

        s = str(json_file).strip()

        # å¦‚æœæ˜¯ä¸å¸¦åˆ†éš”ç¬¦çš„æ–‡ä»¶åï¼Œåˆ™æ‹¼æ¥åˆ° data_dir
        if os.path.sep not in s and "/" not in s and "\\" not in s:
            full_path = os.path.abspath(os.path.join(cls.get_data_dir(), s))
        else:
            full_path = os.path.abspath(s)

        data_dir = os.path.abspath(cls.get_data_dir())
        if not (full_path == data_dir or full_path.startswith(data_dir + os.sep)):
            print(f"âš ï¸ æ‹’ç»è®¿é—® data ç›®å½•å¤–è·¯å¾„: {full_path}")
            return ""

        return full_path

    @classmethod
    def load_json_file(cls, json_file: str) -> List[Dict]:
        """åŠ è½½ JSONï¼ˆå¸¦ mtime ç¼“å­˜è‡ªåŠ¨å¤±æ•ˆï¼‰"""
        full_path = cls._resolve_json_path(json_file)
        if not full_path:
            return []

        if not os.path.exists(full_path):
            print(f"âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨: {full_path}")
            return []

        try:
            mtime = os.path.getmtime(full_path)
            cached = cls._data_cache.get(full_path)
            if cached and cached[0] == mtime:
                return cached[1]

            with open(full_path, "r", encoding="utf-8") as f:
                data = json.load(f)

            if not isinstance(data, list):
                print(f"âŒ æ–‡ä»¶æ ¼å¼é”™è¯¯: æœŸæœ›æ•°ç»„(list)ï¼Œå¾—åˆ° {type(data)}")
                return []

            cls._data_cache[full_path] = (mtime, data)
            print(f"âœ… å·²åŠ è½½: {os.path.basename(full_path)} ({len(data)} ä¸ªè§’è‰²)")
            return data

        except Exception as e:
            print(f"âŒ åŠ è½½æ–‡ä»¶å¤±è´¥: {e}")
            return []

    @classmethod
    def _format_display_name(cls, char: Dict) -> str:
        name_cn = (char.get("name_cn") or "").strip()
        name_en = (char.get("name_en") or "").strip()

        if name_cn and name_en:
            return f"{name_cn} ({name_en})"
        if name_cn:
            return name_cn
        if name_en:
            return name_en
        return "æœªå‘½åè§’è‰²"

    @classmethod
    def get_character_list_for_file(cls, json_file: str) -> List[str]:
        """æ ¹æ®æŒ‡å®š json_file è¿”å›è§’è‰²æ˜¾ç¤ºååˆ—è¡¨"""
        data = cls.load_json_file(json_file)
        if not data:
            return ["æœªåŠ è½½è§’è‰²æ•°æ®"]
        return [cls._format_display_name(c) for c in data]

    @classmethod
    def find_character_by_name(cls, character_name: str, json_file: str) -> Optional[Dict]:
        """æ ¹æ®æ˜¾ç¤ºåæŸ¥æ‰¾è§’è‰²æ•°æ®"""
        data = cls.load_json_file(json_file)
        if not data:
            return None

        target = (character_name or "").strip()
        for char in data:
            if cls._format_display_name(char) == target:
                return char
        return None

    @classmethod
    def create_placeholder_image(cls, width: int = 512, height: int = 512) -> torch.Tensor:
        """åˆ›å»ºå ä½å›¾ï¼š[1,H,W,3] float32, 0..1"""
        img_array = np.full((height, width, 3), 128, dtype=np.uint8)
        img_tensor = torch.from_numpy(img_array).to(torch.float32) / 255.0
        return img_tensor.unsqueeze(0)

    @classmethod
    def _pil_to_comfy_tensor(cls, img: Image.Image, max_side: int = 512) -> torch.Tensor:
        """PIL -> [1,H,W,3] float32 0..1ï¼Œé¡ºæ‰‹é™åˆ¶æœ€å¤§è¾¹é¿å…å¤ªå¤§"""
        if img.mode != "RGB":
            img = img.convert("RGB")

        if max_side and max(img.size) > max_side:
            img.thumbnail((max_side, max_side), Image.LANCZOS)

        arr = np.asarray(img, dtype=np.uint8)
        if arr.ndim != 3 or arr.shape[2] != 3:
            # å…œåº•ï¼šå¼ºåˆ¶è½¬æˆ 3 é€šé“
            arr = np.stack([arr] * 3, axis=-1) if arr.ndim == 2 else arr[:, :, :3]

        tensor = torch.from_numpy(arr).to(torch.float32) / 255.0
        return tensor.unsqueeze(0)

    @classmethod
    def _get_disk_cache_dir(cls) -> str:
        """
        å›¾ç‰‡ç¡¬ç›˜ç¼“å­˜ç›®å½•
        """
        # current_dir = os.path.dirname(os.path.abspath(__file__))
        d = os.path.join(folder_paths.get_temp_directory(), "character_tag_selector")
        os.makedirs(d, exist_ok=True)
        return d

    @classmethod
    def _url_to_cache_key(cls, url: str) -> str:
        return hashlib.md5(url.encode("utf-8")).hexdigest()

    @classmethod
    def _cache_paths_for_url(cls, url: str) -> Tuple[str, str]:
        """
        è¿”å› (webp_path, sha256_path)
        """
        key = cls._url_to_cache_key(url)
        base = os.path.join(cls._get_disk_cache_dir(), key)
        return base + ".webp", base + ".sha256"

    @classmethod
    def _sha256_bytes(cls, b: bytes) -> str:
        h = hashlib.sha256()
        h.update(b)
        return h.hexdigest()

    @classmethod
    def _sha256_file(cls, path: str) -> str:
        h = hashlib.sha256()
        with open(path, "rb") as f:
            for chunk in iter(lambda: f.read(1024 * 1024), b""):
                h.update(chunk)
        return h.hexdigest()

    @classmethod
    def _get_url_lock(cls, cache_key: str) -> threading.Lock:
        with cls._url_locks_guard:
            lk = cls._url_locks.get(cache_key)
            if lk is None:
                lk = threading.Lock()
                cls._url_locks[cache_key] = lk
            return lk

    @classmethod
    def _estimate_tensor_bytes(cls, t: torch.Tensor) -> int:
        # float32: 4 bytes/elemï¼›ä½†åˆ«å‡è®¾ dtypeï¼Œç›´æ¥ç”¨ element_size æ›´ç¨³
        return int(t.numel() * t.element_size())

    @classmethod
    def _lru_put_tensor(cls, key: str, tensor: torch.Tensor) -> None:
        """
        å†™å…¥å†…å­˜ LRUï¼Œå¹¶æ‰§è¡Œé©±é€ï¼Œä¸¥æ ¼é™åˆ¶ items + bytesã€‚
        """
        if key in cls._tensor_lru:
            old = cls._tensor_lru.pop(key)
            cls._tensor_lru_bytes -= cls._estimate_tensor_bytes(old)

        cls._tensor_lru[key] = tensor
        cls._tensor_lru.move_to_end(key, last=True)
        cls._tensor_lru_bytes += cls._estimate_tensor_bytes(tensor)

        # é©±é€ï¼šå…ˆæŒ‰ itemsï¼Œå†æŒ‰ bytesï¼ˆä¸¤è€…éƒ½æ»¡è¶³ï¼‰
        while len(cls._tensor_lru) > cls._MAX_MEM_CACHE_ITEMS or cls._tensor_lru_bytes > cls._MAX_MEM_CACHE_BYTES:
            k, v = cls._tensor_lru.popitem(last=False)
            cls._tensor_lru_bytes -= cls._estimate_tensor_bytes(v)

    @classmethod
    def _lru_get_tensor(cls, key: str) -> Optional[torch.Tensor]:
        t = cls._tensor_lru.get(key)
        if t is None:
            return None
        cls._tensor_lru.move_to_end(key, last=True)
        return t

    @classmethod
    def _load_tensor_from_disk_webp(cls, webp_path: str) -> Optional[torch.Tensor]:
        if not os.path.exists(webp_path):
            return None
        try:
            img = Image.open(webp_path)
            # ç¡®ä¿çœŸæ­£è§£ç ï¼Œé¿å…åªè¯»åˆ° header
            img.load()
            return cls._pil_to_comfy_tensor(img, max_side=512)
        except Exception as e:
            print(f"âŒ ç¡¬ç›˜ç¼“å­˜å›¾ç‰‡æŸå/æ— æ³•è§£ç ï¼Œåˆ é™¤å¹¶å›é€€: {e}")
            try:
                os.remove(webp_path)
            except Exception:
                pass
            return None

    @classmethod
    def _write_file_atomic(cls, final_path: str, data: bytes) -> None:
        """
        åŸå­å†™å…¥ï¼šå…ˆå†™ tmpï¼Œå† replaceã€‚
        Windows/Linux éƒ½ç›¸å¯¹å®‰å…¨ã€‚
        """
        d = os.path.dirname(final_path)
        os.makedirs(d, exist_ok=True)
        fd, tmp_path = tempfile.mkstemp(prefix=".tmp_", dir=d)
        try:
            with os.fdopen(fd, "wb") as f:
                f.write(data)
            os.replace(tmp_path, final_path)
        finally:
            try:
                if os.path.exists(tmp_path):
                    os.remove(tmp_path)
            except Exception:
                pass
    
    @classmethod
    def download_and_cache_image(cls, icon_url: str) -> torch.Tensor:
        """
        1) å†…å­˜ LRUï¼ˆé™åˆ¶ items/bytesï¼‰
        2) ç¡¬ç›˜ webp æŒä¹…åŒ– + sha256 æ ¡éªŒ
        3) ä¸‹è½½é™åˆ¶æœ€å¤§å­—èŠ‚ + stream + UA headers
        """
        if not icon_url or str(icon_url).strip() == "":
            return cls.create_placeholder_image()

        url = str(icon_url).strip()
        if not (url.startswith("http://") or url.startswith("https://")):
            print(f"âš ï¸ é http/https çš„ icon_urlï¼Œæ‹’ç»: {url}")
            return cls.create_placeholder_image()

        cache_key = cls._url_to_cache_key(url)

        # å…ˆæŸ¥å†…å­˜ LRU
        t = cls._lru_get_tensor(cache_key)
        if t is not None:
            return t

        webp_path, sha_path = cls._cache_paths_for_url(url)

        # å¹¶å‘ä¿æŠ¤ï¼šåŒä¸€ URL åŒæ—¶åªå…è®¸ä¸€ä¸ªçº¿ç¨‹/åç¨‹ä¸‹è½½/è½ç›˜
        lock = cls._get_url_lock(cache_key)
        with lock:
            # è¿›é”åå†æŸ¥ä¸€æ¬¡å†…å­˜ï¼ˆå¯èƒ½å…¶å®ƒçº¿ç¨‹å·²å¡«å……ï¼‰
            t = cls._lru_get_tensor(cache_key)
            if t is not None:
                return t

            # æŸ¥ç¡¬ç›˜ç¼“å­˜ + æ ¡éªŒ sha256
            if os.path.exists(webp_path) and os.path.exists(sha_path):
                try:
                    with open(sha_path, "r", encoding="utf-8") as f:
                        expected = f.read().strip()
                    actual = cls._sha256_file(webp_path)
                    if expected and expected == actual:
                        t = cls._load_tensor_from_disk_webp(webp_path)
                        if t is not None:
                            cls._lru_put_tensor(cache_key, t)
                            return t
                    else:
                        print("âš ï¸ ç¡¬ç›˜ç¼“å­˜ sha256 ä¸åŒ¹é…ï¼Œåˆ é™¤åé‡æ–°ä¸‹è½½")
                        try:
                            os.remove(webp_path)
                        except Exception:
                            pass
                        try:
                            os.remove(sha_path)
                        except Exception:
                            pass
                except Exception as e:
                    print(f"âš ï¸ æ ¡éªŒç¡¬ç›˜ç¼“å­˜å¤±è´¥ï¼Œåˆ é™¤åé‡æ–°ä¸‹è½½: {e}")
                    try:
                        os.remove(webp_path)
                    except Exception:
                        pass
                    try:
                        os.remove(sha_path)
                    except Exception:
                        pass

            # ä¸‹è½½ï¼ˆstream + é™åˆ¶å¤§å°ï¼‰
            try:
                resp = requests.get(
                    url,
                    headers=cls._request_headers,
                    stream=True,
                    timeout=(5, 15),  # è¿æ¥è¶…æ—¶/è¯»å–è¶…æ—¶
                    allow_redirects=True,
                )
                resp.raise_for_status()

                # å¦‚æœ server ç»™äº† Content-Lengthï¼Œå…ˆåšä¸€æ¬¡ç¡¬é™åˆ¶
                cl = resp.headers.get("Content-Length", "")
                if cl.isdigit():
                    if int(cl) > cls._MAX_DOWNLOAD_BYTES:
                        raise ValueError(f"Content-Length={cl} è¶…è¿‡ä¸Šé™ {cls._MAX_DOWNLOAD_BYTES} bytes")

                content_type = (resp.headers.get("Content-Type") or "").lower()
                if content_type and ("image" not in content_type):
                    # æœ‰äº›ç«™ä¸æ ‡å‡†ï¼Œè¿™é‡Œåªåšè½»æç¤ºï¼Œä¸å¼ºæ€ä¹Ÿè¡Œï¼›ä½ æƒ³æ›´ä¸¥å¯ä»¥ç›´æ¥ raise
                    print(f"âš ï¸ Content-Type çœ‹èµ·æ¥ä¸æ˜¯å›¾ç‰‡: {content_type}")

                buf = BytesIO()
                downloaded = 0
                for chunk in resp.iter_content(chunk_size=64 * 1024):
                    if not chunk:
                        continue
                    downloaded += len(chunk)
                    if downloaded > cls._MAX_DOWNLOAD_BYTES:
                        raise ValueError(f"ä¸‹è½½å¤§å°è¶…è¿‡ä¸Šé™ {cls._MAX_DOWNLOAD_BYTES} bytes")
                    buf.write(chunk)

                raw = buf.getvalue()
                if not raw:
                    raise ValueError("ä¸‹è½½å†…å®¹ä¸ºç©º")

                # è§£ç å›¾ç‰‡ï¼ˆé˜²æ­¢åæ•°æ®ï¼‰
                img = Image.open(BytesIO(raw))
                img.load()  # å¼ºåˆ¶è§£ç 

                # è½¬æˆ webp æŒä¹…åŒ–ï¼ˆå¦‚æœç¯å¢ƒ Pillow æ²¡ç¼– WebPï¼Œè¿™é‡Œä¼šæŠ¥é”™ï¼‰
                # å…ˆé™åˆ¶å°ºå¯¸å†å­˜ç›˜ï¼Œé¿å…è¶…å¤§å›¾å ç”¨ç©ºé—´/è§£ç æ…¢
                if img.mode != "RGB":
                    img = img.convert("RGB")
                if max(img.size) > 1024:
                    img.thumbnail((1024, 1024), Image.LANCZOS)

                out_buf = BytesIO()
                try:
                    img.save(out_buf, format="WEBP", quality=90, method=6)
                    webp_bytes = out_buf.getvalue()
                    sha256 = cls._sha256_bytes(webp_bytes)

                    cls._write_file_atomic(webp_path, webp_bytes)
                    cls._write_file_atomic(sha_path, (sha256 + "\n").encode("utf-8"))
                except Exception as e:
                    # WebP ä¸å¯ç”¨æ—¶ï¼šå›é€€ä¸ºâ€œåªèµ°å†…å­˜ tensorâ€ï¼Œä¸æŒä¹…åŒ–ï¼ˆæˆ–ä½ ä¹Ÿå¯æ”¹æˆ PNG æŒä¹…åŒ–ï¼‰
                    print(f"âš ï¸ ä¿å­˜ WEBP å¤±è´¥ï¼ˆå¯èƒ½ Pillow æœªå¯ç”¨ WebPï¼‰ï¼Œå°†åªèµ°å†…å­˜ç¼“å­˜: {e}")

                # æœ€ç»ˆè½¬ tensorï¼ˆæŒ‰ä½ åŸé€»è¾‘é™åˆ¶ 512ï¼‰
                tensor = cls._pil_to_comfy_tensor(img, max_side=512)
                cls._lru_put_tensor(cache_key, tensor)
                return tensor

            except Exception as e:
                print(f"âŒ ä¸‹è½½/å¤„ç†å›¾ç‰‡å¤±è´¥: {e}")
                return cls.create_placeholder_image()
    
    # @classmethod
    # def download_and_cache_image(cls, icon_url: str) -> torch.Tensor:
    #     """ä¸‹è½½å›¾ç‰‡å¹¶ç¼“å­˜ä¸º ComfyUI IMAGE tensor"""
    #     if not icon_url or str(icon_url).strip() == "":
    #         return cls.create_placeholder_image()

    #     url = str(icon_url).strip()
    #     cache_key = hashlib.md5(url.encode("utf-8")).hexdigest()

    #     if cache_key in cls._image_cache:
    #         return cls._image_cache[cache_key]

    #     try:
    #         resp = requests.get(url, timeout=10)
    #         resp.raise_for_status()
    #         img = Image.open(BytesIO(resp.content))
    #         tensor = cls._pil_to_comfy_tensor(img, max_side=512)
    #         cls._image_cache[cache_key] = tensor
    #         return tensor

    #     except Exception as e:
    #         print(f"âŒ ä¸‹è½½/å¤„ç†å›¾ç‰‡å¤±è´¥: {e}")
    #         return cls.create_placeholder_image()

    @classmethod
    def INPUT_TYPES(cls):
        available_files = cls.get_available_json_files()
        default_file = available_files[0] if available_files else "æœªæ‰¾åˆ°JSONæ–‡ä»¶"

        # æ³¨æ„ï¼šè¿™é‡Œåªèƒ½åˆå§‹åŒ–ä¸€æ¬¡ï¼ŒåŠ¨æ€è”åŠ¨éœ€è¦å‰ç«¯ JS å»åˆ·æ–°ä¸‹æ‹‰
        # character_list = cls.get_character_list_for_file(default_file)

        # return {
        #     "required": {
        #         "json_file": (available_files, {"default": default_file}),
        #         "character": (character_list, {"default": character_list[0] if character_list else "æœªåŠ è½½è§’è‰²æ•°æ®"}),
        #         "output_type": (list(cls.OUTPUT_TYPES_MAP.keys()), {"default": "Danbooruæ ‡ç­¾"}),
        #     }
        # }

        
        # åç«¯ç»™â€œå…¨é›†â€ç”¨äºæ ¡éªŒé€šè¿‡ï¼›å‰ç«¯å†æŒ‰ json_file åŠ¨æ€è¿‡æ»¤æ˜¾ç¤º
        all_character_choices = cls.get_all_character_choices()

        # é»˜è®¤å€¼ä»å°½é‡ç”¨é»˜è®¤æ–‡ä»¶çš„ç¬¬ä¸€ä¸ªè§’è‰²ï¼ˆæ›´ç¬¦åˆç›´è§‰ï¼‰
        default_file_characters = cls.get_character_list_for_file(default_file)
        character_default = (
            default_file_characters[0]
            if default_file_characters and default_file_characters[0] != "æœªåŠ è½½è§’è‰²æ•°æ®"
            else all_character_choices[0]
        )

        return {
            "required": {
                "json_file": (available_files, {"default": default_file}),
                "character": (all_character_choices, {"default": character_default}),
                "output_type": (list(cls.OUTPUT_TYPES_MAP.keys()), {"default": "Danbooruæ ‡ç­¾"}),
            }
        }

    RETURN_TYPES = ("STRING", "IMAGE")
    RETURN_NAMES = ("text", "preview_image")
    FUNCTION = "generate_tag"
    CATEGORY = "ğŸ® Character Tags"
    OUTPUT_NODE = True

    def generate_tag(self, json_file: str, character: str, output_type: str) -> Tuple[str, torch.Tensor]:
        placeholder = self.create_placeholder_image()

        char_data = self.find_character_by_name(character, json_file)
        if not char_data:
            return (f"âŒ æœªæ‰¾åˆ°è§’è‰²: {character}", placeholder)

        name_cn = (char_data.get("name_cn") or "").strip()
        name_en = (char_data.get("name_en") or "").strip()
        source_cn = (char_data.get("source_cn") or "").strip()
        source_en = (char_data.get("source_en") or "").strip()
        tag = (char_data.get("tag") or "").strip()
        icon_url = (char_data.get("icon_url") or "").strip()

        preview_image = self.download_and_cache_image(icon_url)
        output_format = self.OUTPUT_TYPES_MAP.get(output_type, "danbooru_tag")

        if output_format == "danbooru_tag":
            if tag:
                return (tag, preview_image)
            # æ²¡æœ‰ tag å°±ç”¨è‹±æ–‡åæ‹¼ä¸€ä¸ªå…œåº•
            base = (name_en or name_cn or "unknown").lower()
            tag_name = (
                base.replace(" ", "_")
                .replace("-", "_")
                .replace(":", "")
                .replace("â€¢", "_")
            )
            tag_name = "_".join(filter(None, tag_name.split("_")))
            source_tag = (char_data.get("source") or source_en or source_cn or "unknown").lower().replace(" ", "_")
            return (f"{tag_name}_({source_tag})", preview_image)

        if output_format == "natural_en":
            src = source_en or source_cn or "Unknown"
            nm = name_en or name_cn or "Unknown"
            return (f"{nm} from {src}", preview_image)

        if output_format == "natural_cn":
            src = source_cn or source_en or "æœªçŸ¥ä½œå“"
            nm = name_cn or name_en or "æœªçŸ¥è§’è‰²"
            return (f"{nm}æ¥è‡ª{src}", preview_image)

        if output_format == "cn_name_source":
            src = source_cn or source_en or ""
            nm = name_cn or name_en or ""
            return (f"{nm}, {src}".strip().strip(","), preview_image)

        return ("âŒ æœªçŸ¥çš„è¾“å‡ºç±»å‹", placeholder)

    @classmethod
    def IS_CHANGED(cls, json_file, character, output_type):
        """
        è®© ComfyUI åœ¨æ–‡ä»¶å˜åŒ–/é€‰æ‹©å˜åŒ–æ—¶åˆ·æ–°ã€‚
        """
        full_path = cls._resolve_json_path(json_file)
        if full_path and os.path.exists(full_path):
            mtime = os.path.getmtime(full_path)
            return f"{full_path}:{mtime}:{character}:{output_type}"
        return f"{json_file}:{character}:{output_type}"


# å¯é€‰ï¼šç»™å‰ç«¯åŠ¨æ€æ‹¿è§’è‰²åˆ—è¡¨ç”¨ï¼ˆä½ çš„ JS è‹¥ç›´æ¥ fetch é™æ€ JSONï¼Œå¯ä»¥ä¸ç”¨ï¼‰
if PromptServer is not None:
    @PromptServer.instance.routes.get("/character_tag_selector/characters")
    async def character_tag_selector_characters(request):
        json_file = request.query.get("json_file", "")
        characters = CharacterTagSelector.get_character_list_for_file(json_file)
        return web.json_response({"characters": characters})


NODE_CLASS_MAPPINGS = {
    "CharacterTagSelector": CharacterTagSelector,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "CharacterTagSelector": "ğŸ® Character Tag Selector",
}